# ğŸ’¡ Customer Churn Prediction using Artificial Neural Network (ANN)

This project is an interactive **Streamlit web application** that predicts whether a customer will **leave a bank (churn)** or **stay**, using a trained **Artificial Neural Network (ANN)** built with TensorFlow and Keras.

It is designed to demonstrate how deep learning models can be deployed as a simple web app for real-time predictions.

---

## ğŸ§  What This Project Does

The goal of this project is to:
- Predict customer churn (Yes/No) based on various features.
- Allow users to input data via a **Streamlit interface**.
- Use a pre-trained **ANN model (`model.h5`)** to make predictions.
- Load previously trained **encoders** and **scalers** (`.pkl` files) for preprocessing user inputs.

This project is a complete machine learning pipeline â€” from preprocessing to model deployment.

---

## âš™ï¸ How the Code Works

### ğŸ§© 1. Data Preprocessing
Before training, the data is cleaned and encoded:
- **Categorical features** (like Geography, Gender) are transformed using **OneHotEncoder**.
- **Numerical features** are standardized using **StandardScaler**.
- These encoders and the scaler are saved using **Pickle** so they can be reused during prediction:
  ```python
  with open('scaler.pkl', 'rb') as file:
      scaler = pickle.load(file)
ğŸ§  2. Model Training (Offline)

An Artificial Neural Network (ANN) was trained using TensorFlow/Keras:

Input Layer â†’ Hidden Layers â†’ Output Layer (Sigmoid activation)

Binary classification: churn or not churn

Model saved as model.h5 after training:
'''python
model.save('model.h5')


ğŸ’» 3. Streamlit App (Online Prediction)

In app.py:

The trained model and preprocessing objects are loaded.

Streamlit provides input fields for user data.

User inputs are encoded and scaled.

The model predicts churn probability and displays the result in real time.

Example snippet:

model = tf.keras.models.load_model('model.h5')
with open('onehot_encoder_geo.pkl', 'rb') as file:
    onehot_encoder_geo = pickle.load(file)

ğŸ“ Project Structure
ğŸ“¦ churn-prediction-app
 â”£ ğŸ“„ app.py                   # Streamlit application
 â”£ ğŸ“„ model.h5                 # Trained ANN model
 â”£ ğŸ“„ onehot_encoder_geo.pkl   # Encoder for Geography
 â”£ ğŸ“„ onehot_encoder_gender.pkl # Encoder for Gender (if used)
 â”£ ğŸ“„ scaler.pkl               # StandardScaler for numeric columns
 â”£ ğŸ“„ requirements.txt         # Python dependencies
 â”— ğŸ“„ README.md                # Project documentation

ğŸš€ How to Run the Project
Install Dependencies

Make sure you have Python 3.8+ installed.

ğŸ–¥ï¸ On your computer (VS Code / Command Prompt):
pip install -r requirements.txt

â˜ï¸ On Google Colab:
!pip install -r requirements.txt
